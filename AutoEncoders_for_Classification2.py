# -*- coding: utf-8 -*-
"""HW1_Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L4-WLRt1R4_OGGIzZW7wJBZa_cBRTTot

# 3 - Main

## 3.1
"""

import torch
import torchvision
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get labels for each image in the dataset
labels = [trainset[i][1] for i in range(len(trainset))]

# Count the number of images in each class
counts = [labels.count(i) for i in range(10)]

# Define color map for different classes
colors = ['red', 'blue', 'green', 'purple', 'orange',
          'brown', 'pink', 'gray', 'olive', 'cyan']

# Plot the number-class graph
plt.bar(range(10), counts, color=colors)

# Add text labels for each class
for i in range(10):
    plt.text(i, counts[i] + 100, str(counts[i]), ha='center', fontsize=8)
#     plt.text(i, 4000, str(i), ha='center', fontsize=12)

# Set plot title, axis labels, and limits
plt.title('Number of Images in each Class (MNIST Trainset)')
plt.xlabel('Class')
plt.ylabel('Number of Images')
plt.ylim(0, 10000)

# Set x-axis ticks and labels
plt.xticks(range(10), [str(i) for i in range(10)])

# Save and show plot
plt.savefig('numberclassgraph.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images[i]
    if hasattr(img, 'shape'):
        if len(img.shape) == 3 and img.shape[0] == 1:
            img = img.squeeze(0)
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverand.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt
import torchvision.transforms as transforms

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Calculate mean and standard deviation of the training set
train_data = trainset.data.numpy()
mean = train_data.mean() / 255.0
std = train_data.std() / 255.0

# Define data transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Apply the data transformation to the images
images_normalized = [transform(img) for img in images]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images_normalized[i].numpy().squeeze()
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverandnormal.pdf')
plt.show()

import torchvision.datasets as datasets

# Load MNIST training dataset
trainset = datasets.MNIST(root='./data', train=True, download=True)

# Get the first image in the dataset
image, label = trainset[0]

# Calculate the height and width of the image
height, width = image.size

# Print the result
print("Each data of MNIST has {} x {} = {} features.".format(height, width, height*width))

"""## 3.2"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable

# Hyperparameters
num_epochs = 20
batch_size = 128
learning_rate = 0.0003

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object
autoencoder = Autoencoder()

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    for i, (images, _) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        optimizer.zero_grad()
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    train_loss.append(total_loss/len(train_loader))

    # Validation
    total_loss = 0
    for i, (images, _) in enumerate(test_loader):
        images = Variable(images.view(-1, 28*28))
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        total_loss += loss.item()

    valid_loss.append(total_loss/len(test_loader))

    print('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'
          .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1]))

# Save the trained model weights
torch.save(autoencoder.state_dict(), 'autoencoder.pth')


# Plot loss
import matplotlib.pyplot as plt
plt.plot(train_loss, label='Train Loss')
plt.plot(valid_loss, label='Valid Loss')
plt.legend()
plt.savefig('Loss.pdf')
plt.show()

"""## 3.3"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
import seaborn as sns
import matplotlib.pyplot as plt

# Hyperparameters
num_epochs = 20
batch_size = 128
learning_rate = 0.0003

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object and load trained parameters
autoencoder = Autoencoder()
autoencoder.load_state_dict(torch.load('autoencoder.pth'))
encoder = autoencoder.encoder

# Classifier model
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.layer1 = nn.Linear(30, 256)
        self.layer2 = nn.Linear(256, 128)
        self.layer3 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = nn.functional.relu(x)
        x = self.layer2(x)
        x = nn.functional.relu(x)
        x = self.layer3(x)
        return x

# Create classifier object
classifier = Classifier()

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []
train_acc = []
valid_acc = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        features = encoder(images)
        outputs = classifier(features)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_loss.append(total_loss/len(train_loader))
    train_acc.append(correct/total)

    # Validation
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = Variable(images.view(-1, 28*28))
            labels = Variable(labels)
            features = encoder(images)
            outputs = classifier(features)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    valid_loss.append(total_loss/len(test_loader))
    valid_acc.append(correct/total)

    # Print statistics
    print ('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, Train Acc: {:.4f}, Valid Acc: {:.4f}'
           .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1], train_acc[-1], valid_acc[-1]))

# Save the trained model weights
torch.save(classifier.state_dict(), 'classifier.pth')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Train')
plt.plot(valid_loss, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_acc, label='Train')
plt.plot(valid_acc, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('LossAccur2.pdf')
plt.show()

# Evaluate the model
y_true = []
y_pred = []
with torch.no_grad():
    for images, labels in test_loader:
        images = Variable(images.view(-1, 28*28))
        labels = labels.numpy().tolist()
        features = encoder(images)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
        predicted = predicted.numpy().tolist()
        y_true.extend(labels)
        y_pred.extend(predicted)

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()

# Report metrics
f1 = f1_score(y_true, y_pred, average='weighted')
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
print('F1 Score:', f1)
print('Precision:', precision)
print('Recall:', recall)

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction0.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction1.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction2.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction3.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction4.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction5.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction6.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction7.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction8.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction9.pdf')
plt.show()

"""# 3 - Main

## 3.1
"""

import torch
import torchvision
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get labels for each image in the dataset
labels = [trainset[i][1] for i in range(len(trainset))]

# Count the number of images in each class
counts = [labels.count(i) for i in range(10)]

# Define color map for different classes
colors = ['red', 'blue', 'green', 'purple', 'orange',
          'brown', 'pink', 'gray', 'olive', 'cyan']

# Plot the number-class graph
plt.bar(range(10), counts, color=colors)

# Add text labels for each class
for i in range(10):
    plt.text(i, counts[i] + 100, str(counts[i]), ha='center', fontsize=8)
#     plt.text(i, 4000, str(i), ha='center', fontsize=12)

# Set plot title, axis labels, and limits
plt.title('Number of Images in each Class (MNIST Trainset)')
plt.xlabel('Class')
plt.ylabel('Number of Images')
plt.ylim(0, 10000)

# Set x-axis ticks and labels
plt.xticks(range(10), [str(i) for i in range(10)])

# Save and show plot
plt.savefig('numberclassgraph.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images[i]
    if hasattr(img, 'shape'):
        if len(img.shape) == 3 and img.shape[0] == 1:
            img = img.squeeze(0)
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverand.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt
import torchvision.transforms as transforms

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Calculate mean and standard deviation of the training set
train_data = trainset.data.numpy()
mean = train_data.mean() / 255.0
std = train_data.std() / 255.0

# Define data transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Apply the data transformation to the images
images_normalized = [transform(img) for img in images]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images_normalized[i].numpy().squeeze()
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverandnormal.pdf')
plt.show()

import torchvision.datasets as datasets

# Load MNIST training dataset
trainset = datasets.MNIST(root='./data', train=True, download=True)

# Get the first image in the dataset
image, label = trainset[0]

# Calculate the height and width of the image
height, width = image.size

# Print the result
print("Each data of MNIST has {} x {} = {} features.".format(height, width, height*width))

"""## 3.2"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable

# Hyperparameters
num_epochs = 30
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object
autoencoder = Autoencoder()

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    for i, (images, _) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        optimizer.zero_grad()
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    train_loss.append(total_loss/len(train_loader))

    # Validation
    total_loss = 0
    for i, (images, _) in enumerate(test_loader):
        images = Variable(images.view(-1, 28*28))
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        total_loss += loss.item()

    valid_loss.append(total_loss/len(test_loader))

    print('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'
          .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1]))

# Save the trained model weights
torch.save(autoencoder.state_dict(), 'autoencoder.pth')

# Plot loss
import matplotlib.pyplot as plt
plt.plot(train_loss, label='Train Loss')
plt.plot(valid_loss, label='Valid Loss')
plt.legend()
plt.savefig('Loss.pdf')
plt.show()

"""## 3.3"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
import seaborn as sns
import matplotlib.pyplot as plt

# Hyperparameters
num_epochs = 30
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object and load trained parameters
autoencoder = Autoencoder()
autoencoder.load_state_dict(torch.load('autoencoder.pth'))
encoder = autoencoder.encoder

# Classifier model
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.layer1 = nn.Linear(30, 256)
        self.layer2 = nn.Linear(256, 128)
        self.layer3 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = nn.functional.relu(x)
        x = self.layer2(x)
        x = nn.functional.relu(x)
        x = self.layer3(x)
        return x

# Create classifier object
classifier = Classifier()

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []
train_acc = []
valid_acc = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        features = encoder(images)
        outputs = classifier(features)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_loss.append(total_loss/len(train_loader))
    train_acc.append(correct/total)

    # Validation
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = Variable(images.view(-1, 28*28))
            labels = Variable(labels)
            features = encoder(images)
            outputs = classifier(features)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    valid_loss.append(total_loss/len(test_loader))
    valid_acc.append(correct/total)

    # Print statistics
    print ('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, Train Acc: {:.4f}, Valid Acc: {:.4f}'
           .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1], train_acc[-1], valid_acc[-1]))

# Save the trained model weights
torch.save(classifier.state_dict(), 'classifier.pth')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Train')
plt.plot(valid_loss, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_acc, label='Train')
plt.plot(valid_acc, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('LossAccur2.pdf')
plt.show()

# Evaluate the model
y_true = []
y_pred = []
with torch.no_grad():
    for images, labels in test_loader:
        images = Variable(images.view(-1, 28*28))
        labels = labels.numpy().tolist()
        features = encoder(images)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
        predicted = predicted.numpy().tolist()
        y_true.extend(labels)
        y_pred.extend(predicted)

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()

# Report metrics
f1 = f1_score(y_true, y_pred, average='weighted')
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
print('F1 Score:', f1)
print('Precision:', precision)
print('Recall:', recall)

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction22.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction555.pdf')
plt.show()

"""# 3 - Main

## 3.2
"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable

# Hyperparameters
num_epochs = 100
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 250),
            nn.ReLU(True),
            nn.Linear(250, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 250),
            nn.ReLU(True),
            nn.Linear(250, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object
autoencoder = Autoencoder()

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    for i, (images, _) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        optimizer.zero_grad()
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    train_loss.append(total_loss/len(train_loader))

    # Validation
    total_loss = 0
    for i, (images, _) in enumerate(test_loader):
        images = Variable(images.view(-1, 28*28))
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        total_loss += loss.item()

    valid_loss.append(total_loss/len(test_loader))

    print('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'
          .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1]))

# Save the trained model weights
torch.save(autoencoder.state_dict(), 'autoencoder.pth')

# Plot loss
import matplotlib.pyplot as plt
plt.plot(train_loss, label='Train Loss')
plt.plot(valid_loss, label='Valid Loss')
plt.legend()
plt.savefig('Loss.pdf')
plt.show()

"""## 3.3"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
import seaborn as sns
import matplotlib.pyplot as plt

# Hyperparameters
num_epochs = 100
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 250),
            nn.ReLU(True),
            nn.Linear(250, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 250),
            nn.ReLU(True),
            nn.Linear(250, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object and load trained parameters
autoencoder = Autoencoder()
autoencoder.load_state_dict(torch.load('autoencoder.pth'))
encoder = autoencoder.encoder

# Classifier model
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.layer1 = nn.Linear(30, 128)
        self.layer2 = nn.Linear(128, 64)
        self.layer3 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = nn.functional.relu(x)
        x = self.layer2(x)
        x = nn.functional.relu(x)
        x = self.layer3(x)
        return x

# Create classifier object
classifier = Classifier()

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []
train_acc = []
valid_acc = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        features = encoder(images)
        outputs = classifier(features)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_loss.append(total_loss/len(train_loader))
    train_acc.append(correct/total)

    # Validation
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = Variable(images.view(-1, 28*28))
            labels = Variable(labels)
            features = encoder(images)
            outputs = classifier(features)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    valid_loss.append(total_loss/len(test_loader))
    valid_acc.append(correct/total)

    # Print statistics
    print ('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, Train Acc: {:.4f}, Valid Acc: {:.4f}'
           .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1], train_acc[-1], valid_acc[-1]))

# Save the trained model weights
torch.save(classifier.state_dict(), 'classifier.pth')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Train')
plt.plot(valid_loss, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_acc, label='Train')
plt.plot(valid_acc, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('LossAccur2.pdf')
plt.show()

# Evaluate the model
y_true = []
y_pred = []
with torch.no_grad():
    for images, labels in test_loader:
        images = Variable(images.view(-1, 28*28))
        labels = labels.numpy().tolist()
        features = encoder(images)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
        predicted = predicted.numpy().tolist()
        y_true.extend(labels)
        y_pred.extend(predicted)

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()

# Report metrics
f1 = f1_score(y_true, y_pred, average='weighted')
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
print('F1 Score:', f1)
print('Precision:', precision)
print('Recall:', recall)

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction22.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction000.pdf')
plt.show()

"""# 3 - Other (Soultion 2)"""

import torch
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import random

# Define a transform to normalize the data
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.5,), (0.5,))])

# Load the MNIST dataset with the transform
trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)

# Create a data loader for the train set
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

# Plot 5 random instances from the dataset
images = []
for image, label in trainloader:
    images.extend(image)
    if len(images) >= 5:
        break
plt.figure(figsize=(10,5))
plt.suptitle("Examples of MNIST dataset")
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(images[i].numpy().squeeze(), cmap='gray_r')
    plt.axis('off')
plt.show()



"""autoencoder mohasbe validation loss dar laye akhar """

import torch
from torchvision import datasets, transforms
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# Define the autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 256),
            nn.ReLU(True),
            nn.Linear(256,100),
            nn.ReLU(True),
            nn.Linear(100, 30))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100,256),
            nn.ReLU(True),
            nn.Linear(256, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0,), (1,))])

# Load the MNIST dataset
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)

# Create a data loader for the training dataset
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)

# Instantiate the autoencoder model
autoencoder = Autoencoder()

# Define the loss function
criterion = nn.MSELoss()

# Define the optimizer
optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)

# Train the autoencoder
num_epochs = 20
losses = []
val_losses = []
for epoch in range(num_epochs):
    running_loss = 0.0
    for data in train_loader:
        img, _ = data
        img = img.view(img.size(0), -1)
        optimizer.zero_grad()
        outputs = autoencoder(img)
        loss = criterion(outputs, img)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    losses.append(running_loss / len(train_loader))
    # Calculate the validation loss for the last layer
    val_loss = criterion(outputs[:, -30:], img[:, -30:])
    val_losses.append(val_loss.item())

    # Print the average loss for the epoch
    print('Epoch [{}/{}], Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, num_epochs, running_loss / len(train_loader), val_loss.item()))

# Plot the loss and validation loss
plt.plot(losses, label='Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""code jodda konande output encoder """

import torch
autoencoder = Autoencoder()
# Step 1: Load your pre-trained autoencoder model
autoencoder = torch.load('eutoencoder.pth')

# Step 2: Access the encoder part of the model
encoder = autoencoder.encoder

# Step 3: Load or generate the data that you want to obtain the encoder unit output for
x_data = torch.randn(100, 784) # example data

# Step 4: Pass the data through the encoder layer(s) to obtain the encoded representations
encoded_data = encoder(x_data)

# Step 5: Save the encoded representations to a file or data structure for later reuse
torch.save(encoded_data, 'encoded_data.pth')

import torch

# Load the encoded data from the saved file
encoded_data = torch.load('encoded_data.pth')

# Use the encoded data for another task or model
# ...

torch.save(autoencoder, 'eutoencoder.pth')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0,), (1,))])

"""code mad nazer tamrin"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0,), (1,))])
# Load data
train_dataset = MNIST(root='content/encoded_data.pth/', train=True, transform=ToTensor(), download=True)
test_dataset = MNIST(root='./data', train=False, transform=ToTensor(), download=True)

# Set hyperparameters
batch_size = 128
num_epochs = 10
learning_rate = 0.001

# Create dataloaders
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# Define neural network model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(-1, 784)
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Instantiate model and loss function
model = Net().to(device)
criterion = nn.CrossEntropyLoss()

# Instantiate optimizer
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Train the model
train_loss = []
train_acc = []
val_loss = []
val_acc = []
total_step = len(train_loader)
for epoch in range(num_epochs):
    # Training loop
    running_loss = 0.0
    running_corrects = 0
    for i, (images, labels) in enumerate(train_loader):
        # Move images and labels to device
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Compute accuracy and loss
        _, preds = torch.max(outputs.data, 1)
        running_loss += loss.item() * images.size(0)
        running_corrects += torch.sum(preds == labels.data)

    # Compute training loss and accuracy
    epoch_loss = running_loss / len(train_loader.dataset)
    epoch_acc = running_corrects.double() / len(train_loader.dataset)
    train_loss.append(epoch_loss)
    train_acc.append(epoch_acc)

    # Validation loop
    val_running_loss = 0.0
    val_running_corrects = 0
    with torch.no_grad():
        for images, labels in test_loader:
            # Move images and labels to device
            images = images.to(device)
            labels = labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Compute accuracy and loss
            _, preds = torch.max(outputs.data, 1)
            val_running_loss += loss.item() * images.size(0)
            val_running_corrects += torch.sum(preds == labels.data)

    # Compute validation loss and accuracy
    val_loss.append(val_running_loss / len(test_loader.dataset))
   
    val_epoch_loss = val_running_loss / len(test_loader.dataset)
    val_epoch_acc = val_running_corrects.double() / len(test_loader.dataset)
    val_loss.append(val_epoch_loss)
    val_acc.append(val_epoch_acc)

    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'
          .format(epoch+1, num_epochs, i+1, total_step, epoch_loss, epoch_acc, val_epoch_loss, val_epoch_acc))

# Plot the training and validation accuracy and loss
plt.figure(figsize=(10, 5))
plt.title("Training and Validation Loss")
plt.plot(train_loss, label="Training Loss")
plt.plot(val_loss, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("Training and Validation Accuracy")
plt.plot(train_acc, label="Training Accuracy")
plt.plot(val_acc, label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# Test the model
model.eval()
y_pred = []
y_true = []
with torch.no_grad():
    for images, labels in test_loader:
        # Move images and labels to device
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)

        # Compute predicted label and add to list
        _, preds = torch.max(outputs.data, 1)
        y_pred += preds.cpu().numpy().tolist()
        y_true += labels.cpu().numpy().tolist()

    model.eval()
with torch.no_grad():
     correct = 0
     total = 0
     for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

# Calculate test accuracy
test_acc = 100 * correct / total

# Print test accuracy
#print('Test Accuracy: {:.2f}%'.format(test_acc))


# Plot the confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()

# Print test accuracy
print('Test Accuracy: {:.2f}%'.format(test_acc))

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load data
train_dataset = MNIST(root='./data', train=True, transform=ToTensor(), download=True)
test_dataset = MNIST(root='./data', train=False, transform=ToTensor(), download=True)

# Set hyperparameters
batch_size = 128
num_epochs = 10
learning_rate = 0.002

# Create dataloaders
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# Define neural network model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(-1, 784)
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Instantiate model and loss function
model = Net().to(device)
criterion = nn.CrossEntropyLoss()

# Instantiate optimizer
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Train the model
train_loss = []
train_acc = []
val_loss = []
val_acc = []
total_step = len(train_loader)
for epoch in range(num_epochs):
    # Training loop
    running_loss = 0.0
    running_corrects = 0
    for i, (images, labels) in enumerate(train_loader):
        # Move images and labels to device
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Compute accuracy and loss
        _, preds = torch.max(outputs.data, 1)
        running_loss += loss.item() * images.size(0)
        running_corrects += torch.sum(preds == labels.data)

    # Compute training loss and accuracy
    epoch_loss = running_loss / len(train_loader.dataset)
    epoch_acc = running_corrects.double() / len(train_loader.dataset)
    train_loss.append(epoch_loss)
    train_acc.append(epoch_acc)

    # Validation loop
    val_running_loss = 0.0
    val_running_corrects = 0
    with torch.no_grad():
        for images, labels in test_loader:
            # Move images and labels to device
            images = images.to(device)
            labels = labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Compute accuracy and loss
            _, preds = torch.max(outputs.data, 1)
            val_running_loss += loss.item() * images.size(0)
            val_running_corrects += torch.sum(preds == labels.data)

    # Compute validation loss and accuracy
    val_loss.append(val_running_loss / len(test_loader.dataset))
   
    val_epoch_loss = val_running_loss / len(test_loader.dataset)
    val_epoch_acc = val_running_corrects.double() / len(test_loader.dataset)
    val_loss.append(val_epoch_loss)
    val_acc.append(val_epoch_acc)

    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'
          .format(epoch+1, num_epochs, i+1, total_step, epoch_loss, epoch_acc, val_epoch_loss, val_epoch_acc))

# Plot the training and validation accuracy and loss
plt.figure(figsize=(10, 5))
plt.title("Training and Validation Loss")
plt.plot(train_loss, label="Training Loss")
plt.plot(val_loss, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("Training and Validation Accuracy")
plt.plot(train_acc, label="Training Accuracy")
plt.plot(val_acc, label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# Test the model
model.eval()
y_pred = []
y_true = []
with torch.no_grad():
    for images, labels in test_loader:
        # Move images and labels to device
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)

        # Compute predicted label and add to list
        _, preds = torch.max(outputs.data, 1)
        y_pred += preds.cpu().numpy().tolist()
        y_true += labels.cpu().numpy().tolist()

# Plot the confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()