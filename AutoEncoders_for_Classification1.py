# -*- coding: utf-8 -*-
"""HW1_Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L4-WLRt1R4_OGGIzZW7wJBZa_cBRTTot

# 3 - Main

## 3.1
"""

import torch
import torchvision
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get labels for each image in the dataset
labels = [trainset[i][1] for i in range(len(trainset))]

# Count the number of images in each class
counts = [labels.count(i) for i in range(10)]

# Define color map for different classes
colors = ['red', 'blue', 'green', 'purple', 'orange',
          'brown', 'pink', 'gray', 'olive', 'cyan']

# Plot the number-class graph
plt.bar(range(10), counts, color=colors)

# Add text labels for each class
for i in range(10):
    plt.text(i, counts[i] + 100, str(counts[i]), ha='center', fontsize=8)
#     plt.text(i, 4000, str(i), ha='center', fontsize=12)

# Set plot title, axis labels, and limits
plt.title('Number of Images in each Class (MNIST Trainset)')
plt.xlabel('Class')
plt.ylabel('Number of Images')
plt.ylim(0, 10000)

# Set x-axis ticks and labels
plt.xticks(range(10), [str(i) for i in range(10)])

# Save and show plot
plt.savefig('numberclassgraph.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images[i]
    if hasattr(img, 'shape'):
        if len(img.shape) == 3 and img.shape[0] == 1:
            img = img.squeeze(0)
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverand.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt
import torchvision.transforms as transforms

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Calculate mean and standard deviation of the training set
train_data = trainset.data.numpy()
mean = train_data.mean() / 255.0
std = train_data.std() / 255.0

# Define data transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Apply the data transformation to the images
images_normalized = [transform(img) for img in images]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images_normalized[i].numpy().squeeze()
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverandnormal.pdf')
plt.show()

import torchvision.datasets as datasets

# Load MNIST training dataset
trainset = datasets.MNIST(root='./data', train=True, download=True)

# Get the first image in the dataset
image, label = trainset[0]

# Calculate the height and width of the image
height, width = image.size

# Print the result
print("Each data of MNIST has {} x {} = {} features.".format(height, width, height*width))

"""## 3.2"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable

# Hyperparameters
num_epochs = 20
batch_size = 128
learning_rate = 0.0003

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object
autoencoder = Autoencoder()

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    for i, (images, _) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        optimizer.zero_grad()
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    train_loss.append(total_loss/len(train_loader))

    # Validation
    total_loss = 0
    for i, (images, _) in enumerate(test_loader):
        images = Variable(images.view(-1, 28*28))
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        total_loss += loss.item()

    valid_loss.append(total_loss/len(test_loader))

    print('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'
          .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1]))

# Save the trained model weights
torch.save(autoencoder.state_dict(), 'autoencoder.pth')


# Plot loss
import matplotlib.pyplot as plt
plt.plot(train_loss, label='Train Loss')
plt.plot(valid_loss, label='Valid Loss')
plt.legend()
plt.savefig('Loss.pdf')
plt.show()

"""## 3.3"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
import seaborn as sns
import matplotlib.pyplot as plt

# Hyperparameters
num_epochs = 20
batch_size = 128
learning_rate = 0.0003

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object and load trained parameters
autoencoder = Autoencoder()
autoencoder.load_state_dict(torch.load('autoencoder.pth'))
encoder = autoencoder.encoder

# Classifier model
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.layer1 = nn.Linear(30, 256)
        self.layer2 = nn.Linear(256, 128)
        self.layer3 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = nn.functional.relu(x)
        x = self.layer2(x)
        x = nn.functional.relu(x)
        x = self.layer3(x)
        return x

# Create classifier object
classifier = Classifier()

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []
train_acc = []
valid_acc = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        features = encoder(images)
        outputs = classifier(features)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_loss.append(total_loss/len(train_loader))
    train_acc.append(correct/total)

    # Validation
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = Variable(images.view(-1, 28*28))
            labels = Variable(labels)
            features = encoder(images)
            outputs = classifier(features)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    valid_loss.append(total_loss/len(test_loader))
    valid_acc.append(correct/total)

    # Print statistics
    print ('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, Train Acc: {:.4f}, Valid Acc: {:.4f}'
           .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1], train_acc[-1], valid_acc[-1]))

# Save the trained model weights
torch.save(classifier.state_dict(), 'classifier.pth')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Train')
plt.plot(valid_loss, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_acc, label='Train')
plt.plot(valid_acc, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('LossAccur2.pdf')
plt.show()

# Evaluate the model
y_true = []
y_pred = []
with torch.no_grad():
    for images, labels in test_loader:
        images = Variable(images.view(-1, 28*28))
        labels = labels.numpy().tolist()
        features = encoder(images)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
        predicted = predicted.numpy().tolist()
        y_true.extend(labels)
        y_pred.extend(predicted)

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()

# Report metrics
f1 = f1_score(y_true, y_pred, average='weighted')
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
print('F1 Score:', f1)
print('Precision:', precision)
print('Recall:', recall)

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction0.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction1.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction2.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction3.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction4.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction5.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction6.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction7.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction8.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction9.pdf')
plt.show()

"""# 3 - Main

## 3.1
"""

import torch
import torchvision
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get labels for each image in the dataset
labels = [trainset[i][1] for i in range(len(trainset))]

# Count the number of images in each class
counts = [labels.count(i) for i in range(10)]

# Define color map for different classes
colors = ['red', 'blue', 'green', 'purple', 'orange',
          'brown', 'pink', 'gray', 'olive', 'cyan']

# Plot the number-class graph
plt.bar(range(10), counts, color=colors)

# Add text labels for each class
for i in range(10):
    plt.text(i, counts[i] + 100, str(counts[i]), ha='center', fontsize=8)
#     plt.text(i, 4000, str(i), ha='center', fontsize=12)

# Set plot title, axis labels, and limits
plt.title('Number of Images in each Class (MNIST Trainset)')
plt.xlabel('Class')
plt.ylabel('Number of Images')
plt.ylim(0, 10000)

# Set x-axis ticks and labels
plt.xticks(range(10), [str(i) for i in range(10)])

# Save and show plot
plt.savefig('numberclassgraph.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images[i]
    if hasattr(img, 'shape'):
        if len(img.shape) == 3 and img.shape[0] == 1:
            img = img.squeeze(0)
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverand.pdf')
plt.show()

import torch
import torchvision
import random
import matplotlib.pyplot as plt
import torchvision.transforms as transforms

# Load MNIST training dataset
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)

# Calculate mean and standard deviation of the training set
train_data = trainset.data.numpy()
mean = train_data.mean() / 255.0
std = train_data.std() / 255.0

# Define data transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

# Get 5 random images and their labels
indices = random.sample(range(len(trainset)), 5)
images = [trainset[i][0] for i in indices]
labels = [trainset[i][1] for i in indices]

# Apply the data transformation to the images
images_normalized = [transform(img) for img in images]

# Plot the images
fig, axs = plt.subplots(1, 5, figsize=(10, 5))
for i in range(5):
    img = images_normalized[i].numpy().squeeze()
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(labels[i]))

# Save and show plot
plt.savefig('fiverandnormal.pdf')
plt.show()

import torchvision.datasets as datasets

# Load MNIST training dataset
trainset = datasets.MNIST(root='./data', train=True, download=True)

# Get the first image in the dataset
image, label = trainset[0]

# Calculate the height and width of the image
height, width = image.size

# Print the result
print("Each data of MNIST has {} x {} = {} features.".format(height, width, height*width))

"""## 3.2"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable

# Hyperparameters
num_epochs = 30
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object
autoencoder = Autoencoder()

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    for i, (images, _) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        optimizer.zero_grad()
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    train_loss.append(total_loss/len(train_loader))

    # Validation
    total_loss = 0
    for i, (images, _) in enumerate(test_loader):
        images = Variable(images.view(-1, 28*28))
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        total_loss += loss.item()

    valid_loss.append(total_loss/len(test_loader))

    print('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'
          .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1]))

# Save the trained model weights
torch.save(autoencoder.state_dict(), 'autoencoder.pth')

# Plot loss
import matplotlib.pyplot as plt
plt.plot(train_loss, label='Train Loss')
plt.plot(valid_loss, label='Valid Loss')
plt.legend()
plt.savefig('Loss.pdf')
plt.show()

"""## 3.3"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
import seaborn as sns
import matplotlib.pyplot as plt

# Hyperparameters
num_epochs = 30
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 300),
            nn.ReLU(True),
            nn.Linear(300, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 300),
            nn.ReLU(True),
            nn.Linear(300, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object and load trained parameters
autoencoder = Autoencoder()
autoencoder.load_state_dict(torch.load('autoencoder.pth'))
encoder = autoencoder.encoder

# Classifier model
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.layer1 = nn.Linear(30, 256)
        self.layer2 = nn.Linear(256, 128)
        self.layer3 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = nn.functional.relu(x)
        x = self.layer2(x)
        x = nn.functional.relu(x)
        x = self.layer3(x)
        return x

# Create classifier object
classifier = Classifier()

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []
train_acc = []
valid_acc = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        features = encoder(images)
        outputs = classifier(features)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_loss.append(total_loss/len(train_loader))
    train_acc.append(correct/total)

    # Validation
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = Variable(images.view(-1, 28*28))
            labels = Variable(labels)
            features = encoder(images)
            outputs = classifier(features)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    valid_loss.append(total_loss/len(test_loader))
    valid_acc.append(correct/total)

    # Print statistics
    print ('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, Train Acc: {:.4f}, Valid Acc: {:.4f}'
           .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1], train_acc[-1], valid_acc[-1]))

# Save the trained model weights
torch.save(classifier.state_dict(), 'classifier.pth')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Train')
plt.plot(valid_loss, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_acc, label='Train')
plt.plot(valid_acc, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('LossAccur2.pdf')
plt.show()

# Evaluate the model
y_true = []
y_pred = []
with torch.no_grad():
    for images, labels in test_loader:
        images = Variable(images.view(-1, 28*28))
        labels = labels.numpy().tolist()
        features = encoder(images)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
        predicted = predicted.numpy().tolist()
        y_true.extend(labels)
        y_pred.extend(predicted)

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()

# Report metrics
f1 = f1_score(y_true, y_pred, average='weighted')
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
print('F1 Score:', f1)
print('Precision:', precision)
print('Recall:', recall)

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction22.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction555.pdf')
plt.show()

"""# 3 - Main

## 3.2
"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable

# Hyperparameters
num_epochs = 100
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 250),
            nn.ReLU(True),
            nn.Linear(250, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 250),
            nn.ReLU(True),
            nn.Linear(250, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object
autoencoder = Autoencoder()

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    for i, (images, _) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        optimizer.zero_grad()
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    train_loss.append(total_loss/len(train_loader))

    # Validation
    total_loss = 0
    for i, (images, _) in enumerate(test_loader):
        images = Variable(images.view(-1, 28*28))
        outputs = autoencoder(images)
        loss = criterion(outputs, images)
        total_loss += loss.item()

    valid_loss.append(total_loss/len(test_loader))

    print('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'
          .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1]))

# Save the trained model weights
torch.save(autoencoder.state_dict(), 'autoencoder.pth')

# Plot loss
import matplotlib.pyplot as plt
plt.plot(train_loss, label='Train Loss')
plt.plot(valid_loss, label='Valid Loss')
plt.legend()
plt.savefig('Loss.pdf')
plt.show()

"""## 3.3"""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
import seaborn as sns
import matplotlib.pyplot as plt

# Hyperparameters
num_epochs = 100
batch_size = 64
learning_rate = 0.0001

# MNIST dataset
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                           train=False,
                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

# Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 500),
            nn.ReLU(True),
            nn.Linear(500, 250),
            nn.ReLU(True),
            nn.Linear(250, 100),
            nn.ReLU(True),
            nn.Linear(100, 30),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(30, 100),
            nn.ReLU(True),
            nn.Linear(100, 250),
            nn.ReLU(True),
            nn.Linear(250, 500),
            nn.ReLU(True),
            nn.Linear(500, 784),
            nn.Sigmoid())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Create autoencoder object and load trained parameters
autoencoder = Autoencoder()
autoencoder.load_state_dict(torch.load('autoencoder.pth'))
encoder = autoencoder.encoder

# Classifier model
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.layer1 = nn.Linear(30, 128)
        self.layer2 = nn.Linear(128, 64)
        self.layer3 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = nn.functional.relu(x)
        x = self.layer2(x)
        x = nn.functional.relu(x)
        x = self.layer3(x)
        return x

# Create classifier object
classifier = Classifier()

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)

# Train the model
train_loss = []
valid_loss = []
train_acc = []
valid_acc = []

for epoch in range(num_epochs):
    # Train
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        features = encoder(images)
        outputs = classifier(features)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_loss.append(total_loss/len(train_loader))
    train_acc.append(correct/total)

    # Validation
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = Variable(images.view(-1, 28*28))
            labels = Variable(labels)
            features = encoder(images)
            outputs = classifier(features)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    valid_loss.append(total_loss/len(test_loader))
    valid_acc.append(correct/total)

    # Print statistics
    print ('Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, Train Acc: {:.4f}, Valid Acc: {:.4f}'
           .format(epoch+1, num_epochs, train_loss[-1], valid_loss[-1], train_acc[-1], valid_acc[-1]))

# Save the trained model weights
torch.save(classifier.state_dict(), 'classifier.pth')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Train')
plt.plot(valid_loss, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_acc, label='Train')
plt.plot(valid_acc, label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('LossAccur2.pdf')
plt.show()

# Evaluate the model
y_true = []
y_pred = []
with torch.no_grad():
    for images, labels in test_loader:
        images = Variable(images.view(-1, 28*28))
        labels = labels.numpy().tolist()
        features = encoder(images)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
        predicted = predicted.numpy().tolist()
        y_true.extend(labels)
        y_pred.extend(predicted)

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('conf.pdf')
plt.show()

# Report metrics
f1 = f1_score(y_true, y_pred, average='weighted')
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
print('F1 Score:', f1)
print('Precision:', precision)
print('Recall:', recall)

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction22.pdf')
plt.show()

import io
import requests
from PIL import Image
import numpy as np

# Define a function to predict the class of an input image
def predict_image(image_path, encoder, classifier):
    # Open and preprocess the image
    img = Image.open(image_path).convert('L')
    img = img.resize((28, 28))
    img_tensor = transforms.ToTensor()(img)
    img_tensor = img_tensor.view(-1, 28*28)
    # Pass the image through the encoder and classifier
    with torch.no_grad():
        features = encoder(img_tensor)
        outputs = classifier(features)
        _, predicted = torch.max(outputs.data, 1)
    # Return the predicted class
    return predicted.item()

# Upload an image and predict its class
from google.colab import files

# Upload the image
uploaded = files.upload()

# Predict the class
image_path = next(iter(uploaded))
predicted_class = predict_image(io.BytesIO(uploaded[image_path]), encoder, classifier)

# Print the predicted class
print('Predicted class:', predicted_class)

# Open the uploaded image
img = Image.open(io.BytesIO(uploaded[image_path]))

# Create a figure with the image and the predicted class as the title
fig, ax = plt.subplots()
ax.imshow(img)
ax.set_title('Predicted Class: {}'.format(predicted_class))

# Save the plot as a pdf
plt.savefig('prediction000.pdf')
plt.show()